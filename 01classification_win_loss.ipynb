{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Win/Loss Classification\n",
    "Using the final dataframe collected and aggregated from FiveThirtyEight, baseball-reference.com, Retrosheet.org, and the NOAA Weather Service, (see data collection/exploration in this repo and in mlb_spread_betting repo) the end goal is to accurately model the spread. The first step in this process will be predicting the game winner, and then using this prediction as a feature to predict the spread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in full data set\n",
    "full_ = pd.read_csv('all_features.csv.gz', compression = 'gzip')\n",
    "#drop merge keys and non-numeric columns\n",
    "full_ = full_.drop(columns = ['date', 'team1', 'team2', 'home_starter', 'road_starter',\n",
    "                             'is_doubleheader', 'is_tripleheader', 'score1', 'score2'])\n",
    "X, y = full_.drop(columns = ['home_loss']), full_['home_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline logistic regression accuracy: 0.5736283947718557\n",
      "\n",
      "Baseline SGD Classifier accuracy 0.4848947327228614\n"
     ]
    }
   ],
   "source": [
    "#split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "#train and test baseline logistic regression model\n",
    "lr = LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n",
    "lr.fit(x_train, y_train)\n",
    "lr_preds = lr.predict(x_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "#train and test baseline SGD Classifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "sgd_preds = sgd.predict(x_test)\n",
    "sgd_accuracy = accuracy_score(y_test, sgd_preds)\n",
    "print('Baseline logistic regression accuracy: {}'.format(lr_accuracy))\n",
    "print()\n",
    "print('Baseline SGD Classifier accuracy {}'.format(sgd_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION- TREE BASED MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the final feature set to use in parameter tuning and model building, I have developed a __FeatureSelector__ object (see __recursive_selection.py__ for a full explanation of this object) to perform recursive features selection. While FeatureSelector offers several different methods of feature selection, with tree-based models I will use the feature importances attribute and iterate through the full feature frame, removing the least important features at each iteration and evaluating the new feature set using 5 fold cross validation with a given metric (in this case, with two balanced classes, it will be accuracy). I will perform this in several different cases: with the full feature frame, reduced feature frame after removing highly correlated features, and the feature frame with features normalized to mean 0 and unit variance. NOTE: Unless otherwise specified with n_jobs parameter, FeatureSelector will run all available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recursive_selection import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "7 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n"
     ]
    }
   ],
   "source": [
    "#generate dictionary of algorithms to select features based on feature importance and specify generic base\n",
    "#parameters to be passed to FeatureSelector object\n",
    "tree_based = {'RandomForestClassifier': (RandomForestClassifier(), {'n_estimators' : 100,\n",
    "                                                                   'max_depth' : 7}),\n",
    "             'LGBMClassifier' : (lgb.LGBMClassifier(), {'num_leaves' : 70,\n",
    "                                                       'max_depth' : 6}),\n",
    "             'XGBClassifier' : (xgb.XGBClassifier(), {'max_depth' : 5,\n",
    "                                                     'n_estimators' : 100})}\n",
    "#function to initialize results dictionary for each algorithm to be called to compare results\n",
    "def initialize_results_dict():\n",
    "    return( {'Algorithm' : None,\n",
    "            'best_eval_full' : None,\n",
    "            'best_subset_full' : None,\n",
    "            'best_eval_drop_corr' : None,\n",
    "            'best_subset_drop_corr' : None})\n",
    "#empty list to store result dictionaries- can be easily made into dataframe using pd.concat\n",
    "results_list = []\n",
    "\n",
    "#iterate through algorithms, use recursive_selection method of FeatureSelector object, first using full feature set,\n",
    "#then eliminating correlated features (with given tolerance)\n",
    "for algo in tree_based:\n",
    "    result = initialize_results_dict()\n",
    "    result['Algorithm'] = algo\n",
    "    selector = FeatureSelector(X, y, algorithm = tree_based[algo][0], params = tree_based[algo][1], drop_size = 10)\n",
    "    selector.recursive_selection()\n",
    "    result['best_eval_full'] = selector.best_eval\n",
    "    result['best_subset_full'] = selector.best_subset\n",
    "    selector = FeatureSelector(X, y, algorithm = tree_based[algo][0], drop_corr = True,\n",
    "                               params = tree_based[algo][1], drop_size = 10, correlation_tolerance = 0.6)\n",
    "    selector.recursive_selection()\n",
    "    result['best_eval_drop_corr'] = selector.best_eval\n",
    "    result['best_subset_drop_corr'] = selector.best_subset\n",
    "    results_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to evaluate results\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>best_eval_full</th>\n",
       "      <th>best_subset_full</th>\n",
       "      <th>best_eval_drop_corr</th>\n",
       "      <th>best_subset_drop_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.573724</td>\n",
       "      <td>Index(['elo1_pre', 'elo_prob1', 'elo_prob2', '...</td>\n",
       "      <td>0.573653</td>\n",
       "      <td>Index(['road_OBPS', 'road_career_ERA', 'elo1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.571153</td>\n",
       "      <td>Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...</td>\n",
       "      <td>0.571029</td>\n",
       "      <td>Index(['home_OBPS', 'elo1_pre', 'elo2_pre', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.573360</td>\n",
       "      <td>Index(['home_OBPS', 'home_AVG_RUNS', 'home_tot...</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>Index(['home_OBPS', 'home_BULLPEN_ERA', 'home_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  best_eval_full  \\\n",
       "0  RandomForestClassifier        0.573724   \n",
       "1          LGBMClassifier        0.571153   \n",
       "2           XGBClassifier        0.573360   \n",
       "\n",
       "                                    best_subset_full  best_eval_drop_corr  \\\n",
       "0  Index(['elo1_pre', 'elo_prob1', 'elo_prob2', '...             0.573653   \n",
       "1  Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...             0.571029   \n",
       "2  Index(['home_OBPS', 'home_AVG_RUNS', 'home_tot...             0.572139   \n",
       "\n",
       "                               best_subset_drop_corr  \n",
       "0  Index(['road_OBPS', 'road_career_ERA', 'elo1_p...  \n",
       "1  Index(['home_OBPS', 'elo1_pre', 'elo2_pre', 'p...  \n",
       "2  Index(['home_OBPS', 'home_BULLPEN_ERA', 'home_...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review dataframe \n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from this table, the highest performing algorithm was the RandomForestClassifier, and the best subset is available. I will run the same method, but this time with a scaled feature frame to test if this improves performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "7 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "5 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n",
      "10 features have been dropped, moving to next iteration\n"
     ]
    }
   ],
   "source": [
    "#new result list\n",
    "results_list = []\n",
    "\n",
    "#iterate through algorithms, use recursive_selection method of FeatureSelector object, first using full feature set,\n",
    "#then eliminating correlated features (with given tolerance), this time with scaled features\n",
    "for algo in tree_based:\n",
    "    result = initialize_results_dict()\n",
    "    result['Algorithm'] = algo\n",
    "    selector = FeatureSelector(X, y, algorithm = tree_based[algo][0], scale = 'standard', \n",
    "                               params = tree_based[algo][1], drop_size = 10)\n",
    "    selector.recursive_selection()\n",
    "    result['best_eval_full'] = selector.best_eval\n",
    "    result['best_subset_full'] = selector.best_subset\n",
    "    selector = FeatureSelector(X, y, algorithm = tree_based[algo][0], scale = 'standard', drop_corr = True,\n",
    "                               params = tree_based[algo][1], drop_size = 10, correlation_tolerance = 0.6)\n",
    "    selector.recursive_selection()\n",
    "    result['best_eval_drop_corr'] = selector.best_eval\n",
    "    result['best_subset_drop_corr'] = selector.best_subset\n",
    "    results_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>best_eval_full</th>\n",
       "      <th>best_subset_full</th>\n",
       "      <th>best_eval_drop_corr</th>\n",
       "      <th>best_subset_drop_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.573958</td>\n",
       "      <td>Index(['elo1_pre', 'elo_prob1', 'elo_prob2', '...</td>\n",
       "      <td>0.573653</td>\n",
       "      <td>Index(['road_OBPS', 'road_career_ERA', 'elo1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.571147</td>\n",
       "      <td>Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...</td>\n",
       "      <td>0.571065</td>\n",
       "      <td>Index(['home_OBPS', 'elo1_pre', 'elo2_pre', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.573201</td>\n",
       "      <td>Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...</td>\n",
       "      <td>0.572978</td>\n",
       "      <td>Index(['home_OBPS', 'home_BULLPEN_ERA', 'home_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  best_eval_full  \\\n",
       "0  RandomForestClassifier        0.573958   \n",
       "1          LGBMClassifier        0.571147   \n",
       "2           XGBClassifier        0.573201   \n",
       "\n",
       "                                    best_subset_full  best_eval_drop_corr  \\\n",
       "0  Index(['elo1_pre', 'elo_prob1', 'elo_prob2', '...             0.573653   \n",
       "1  Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...             0.571065   \n",
       "2  Index(['home_OBPS', 'home_AVG_RUNS', 'home_AVG...             0.572978   \n",
       "\n",
       "                               best_subset_drop_corr  \n",
       "0  Index(['road_OBPS', 'road_career_ERA', 'elo1_p...  \n",
       "1  Index(['home_OBPS', 'elo1_pre', 'elo2_pre', 'p...  \n",
       "2  Index(['home_OBPS', 'home_BULLPEN_ERA', 'home_...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate DataFrame of results for scaled data\n",
    "scaled_results_df = pd.DataFrame(results_list)\n",
    "scaled_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier is again the best performer, and there is no marked improvement from scaling features. Now, I will perform hyperparameter tuning using the RandomForestClassifier and the best subset generated by the FeatureSelector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['elo1_pre', 'elo_prob1', 'elo_prob2', 'rating1_pre', 'rating2_pre',\n",
       "       'pitcher1_rgs', 'pitcher2_rgs', 'rating_prob1', 'rating_prob2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return highest performing subset\n",
    "best_ = results_df.iloc[results_df.best_eval_full.idxmax()]['best_subset_full']\n",
    "#view highest performing subset\n",
    "best_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parameter tuning, I have elected to use the Hyperopt library implementing Bayesian parameter tuning, using the tree-structured Parzen estimator algorithm (https://optunity.readthedocs.io/en/latest/user/solvers/TPE.html#hyperopt). Given a parameter space to search over, the optimizer function below uses the fmin function from the Hyperopt library to minimize an objective function, which in this case is cross validation score of the RandomForestClassifier with a given set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter tuning with hyperopt, generate parameter space to search over\n",
    "hyperopt_space = {'criterion' : hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'n_estimators' : scope.int(hp.quniform('n_estimators', 10, 200, 10)),\n",
    "                  'max_depth' : scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "                  'max_features' : hp.choice('max_features', ['auto', None]),\n",
    "                  'bootstrap' : hp.choice('bootstrap', [True, False]),\n",
    "                  'n_jobs' : -1\n",
    "                 }\n",
    "#optimizer function to call fmin function\n",
    "def rfc_optimizer(param_space, x_train, y_train, num_eval):\n",
    "    #objective function to minimize \n",
    "    def objective(params):\n",
    "        rfc = RandomForestClassifier(**params)\n",
    "        score = cross_val_score(rfc, x_train, y_train, cv = 10).mean()\n",
    "        return({'loss' : -score, 'status' : STATUS_OK})\n",
    "    #initialize trials objects to record performance\n",
    "    trials = Trials()\n",
    "    \n",
    "    best_params = fmin(objective, param_space, algo = tpe.suggest, max_evals = num_eval, trials = trials,\n",
    "                      rstate = np.random.RandomState(32))\n",
    "    \n",
    "    return(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:00:13<00:00, 72.28s/it, best loss: -0.5741168825141509] \n"
     ]
    }
   ],
   "source": [
    "#use best subset generated by feature selection process\n",
    "X_best = X[best_]\n",
    "\n",
    "#call search function\n",
    "best_params = rfc_optimizer(hyperopt_space, X_best, y, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': 0,\n",
       " 'criterion': 0,\n",
       " 'max_depth': 6.0,\n",
       " 'max_features': 0,\n",
       " 'n_estimators': 30.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best parameters\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the best parameters from the search, I will now fit on a training set and test on a holdout set for a final validation accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimized RandomForestClassifier 0.5731392345621038\n"
     ]
    }
   ],
   "source": [
    "#fit final feature set and final parameter set and test performance\n",
    "rfc_optimized = RandomForestClassifier(n_estimators = 30, criterion = 'gini', max_depth = 6, max_features = 'auto',\n",
    "                                      bootstrap = True, n_jobs = -1)\n",
    "\n",
    "#split full dataset into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_best, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#fit on training data\n",
    "rfc_optimized.fit(x_train, y_train)\n",
    "#predict on test data\n",
    "y_pred = rfc_optimized.predict(x_test)\n",
    "#score on validation set\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of optimized RandomForestClassifier {}'.format(accuracy_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did not improve upon the baseline LogisticRegression model. I will try removing features with high colinearity and scaling the features to determine if this will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elo_prob1     elo_prob2       1.000000\n",
       "rating_prob1  rating_prob2    1.000000\n",
       "elo1_pre      rating1_pre     0.995811\n",
       "elo_prob1     rating_prob2    0.970041\n",
       "              rating_prob1    0.970041\n",
       "elo_prob2     rating_prob2    0.970041\n",
       "              rating_prob1    0.970041\n",
       "elo1_pre      elo_prob2       0.742245\n",
       "              elo_prob1       0.742245\n",
       "elo_prob1     rating1_pre     0.739824\n",
       "elo_prob2     rating1_pre     0.739824\n",
       "elo_prob1     rating2_pre     0.736012\n",
       "elo_prob2     rating2_pre     0.736012\n",
       "rating1_pre   rating_prob2    0.722678\n",
       "              rating_prob1    0.722678\n",
       "elo1_pre      rating_prob2    0.719878\n",
       "              rating_prob1    0.719878\n",
       "rating2_pre   rating_prob2    0.719219\n",
       "              rating_prob1    0.719219\n",
       "elo1_pre      pitcher1_rgs    0.354917\n",
       "rating2_pre   pitcher2_rgs    0.350723\n",
       "rating1_pre   pitcher1_rgs    0.349292\n",
       "pitcher2_rgs  rating_prob2    0.288479\n",
       "              rating_prob1    0.288479\n",
       "pitcher1_rgs  rating_prob2    0.285707\n",
       "              rating_prob1    0.285707\n",
       "elo_prob1     pitcher2_rgs    0.251062\n",
       "elo_prob2     pitcher2_rgs    0.251062\n",
       "elo_prob1     pitcher1_rgs    0.246587\n",
       "elo_prob2     pitcher1_rgs    0.246587\n",
       "rating1_pre   rating2_pre     0.098538\n",
       "elo1_pre      rating2_pre     0.097461\n",
       "pitcher1_rgs  pitcher2_rgs    0.020801\n",
       "rating1_pre   pitcher2_rgs    0.016615\n",
       "elo1_pre      pitcher2_rgs    0.016353\n",
       "rating2_pre   pitcher1_rgs    0.009313\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for colinearity in final feature frame\n",
    "best_corr = X_best.corr().abs()\n",
    "all_correlated = best_corr.where(np.triu(np.ones(best_corr.shape), k = 1)\\\n",
    "                              .astype(np.bool)).stack().sort_values(ascending = False)\n",
    "#view colinearity\n",
    "all_correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop highly correlated features\n",
    "X_best = X_best.drop(columns = ['elo_prob2', 'rating_prob2', 'rating1_pre', 'elo_prob1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimized RandomForestClassifier 0.5730609689285435\n"
     ]
    }
   ],
   "source": [
    "#fit final feature set and final parameter set and test performance\n",
    "rfc_optimized = RandomForestClassifier(n_estimators = 30, criterion = 'gini', max_depth = 6, max_features = 'auto',\n",
    "                                      bootstrap = True, n_jobs = -1)\n",
    "\n",
    "#split full dataset into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_best, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#fit on training data\n",
    "rfc_optimized.fit(x_train, y_train)\n",
    "#predict on test data\n",
    "y_pred = rfc_optimized.predict(x_test)\n",
    "#score on validation set\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of optimized RandomForestClassifier {}'.format(accuracy_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimized RandomForestClassifier with scaled features is 0.5735501291382954\n"
     ]
    }
   ],
   "source": [
    "#check if scaling features will have any effect on final accuracy \n",
    "ss = StandardScaler()\n",
    "#fit training data\n",
    "ss.fit(x_train)\n",
    "\n",
    "#scale training and test data\n",
    "x_train_s, x_test_s = ss.transform(x_train), ss.transform(x_test)\n",
    "#reinitialize optimized RFC\n",
    "rfc_optimized = RandomForestClassifier(n_estimators = 30, criterion = 'gini', max_depth = 6, max_features = 'auto',\n",
    "                                      bootstrap = True, n_jobs = -1)\n",
    "#fit on training data\n",
    "rfc_optimized.fit(x_train_s, y_train)\n",
    "#predict on test data\n",
    "y_pred = rfc_optimized.predict(x_test_s)\n",
    "#score on validation set\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy of optimized RandomForestClassifier with scaled features is {}'.format(accuracy_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Detour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First round of feature selection and modeling did not yield much improvement. One of the challenges with using team statistics and team ratings (the majority of the data) is their is high correlation between features. An idea I have had to circumvent this is instead of using ratings, win probability, and statistics for each team, generate a model using the difference between ratings, win probability, and statistics for each team. As the games are played head to head, the discrepancy is what is more intriguing anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of all features\n",
    "all_features = pd.Series(X.columns)\n",
    "#split into list of home/road features, collected from retrosheet\n",
    "home_team_retro = all_features[all_features.str.contains('home')]\n",
    "road_team_retro = all_features[all_features.str.contains('road')]\n",
    "#split into list of home/road features, collected from elo dataset\n",
    "home_team_elo = all_features[all_features.str.contains('1')]\n",
    "road_team_elo = all_features[all_features.str.contains('2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24, 6, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check lengths of features\n",
    "len(home_team_retro), len(road_team_retro), len(home_team_elo), len(road_team_elo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          home_OBPS\n",
       "1                      home_AVG_RUNS\n",
       "2                         home_AVG_H\n",
       "3                   home_BULLPEN_ERA\n",
       "4                  home_BULLPEN_WHIP\n",
       "5           home_BULLPEN_AVG_INNINGS\n",
       "6                    home_total_OBPS\n",
       "7                home_total_AVG_RUNS\n",
       "8                   home_total_AVG_H\n",
       "9             home_total_BULLPEN_ERA\n",
       "10           home_total_BULLPEN_WHIP\n",
       "11    home_total_BULLPEN_AVG_INNINGS\n",
       "24                   home_career_ERA\n",
       "25                  home_career_WHIP\n",
       "26                 home_career_AVGIP\n",
       "27                home_career_ERA_AH\n",
       "28               home_career_WHIP_AH\n",
       "29              home_career_AVGIP_AH\n",
       "30                   home_season_ERA\n",
       "31                  home_season_WHIP\n",
       "32                 home_season_AVGIP\n",
       "33                home_season_ERA_AH\n",
       "34               home_season_WHIP_AH\n",
       "35              home_season_AVGIP_AH\n",
       "69                    home_record_hm\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_team_retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_record is showing up in home_team_features, dropping from axis \n",
    "home_team_retro = home_team_retro.drop(69, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_OBPS</td>\n",
       "      <td>road_OBPS</td>\n",
       "      <td>elo1_pre</td>\n",
       "      <td>elo2_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home_AVG_RUNS</td>\n",
       "      <td>road_AVG_RUNS</td>\n",
       "      <td>elo_prob1</td>\n",
       "      <td>elo_prob2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_AVG_H</td>\n",
       "      <td>road_AVG_H</td>\n",
       "      <td>rating1_pre</td>\n",
       "      <td>rating2_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home_BULLPEN_ERA</td>\n",
       "      <td>road_BULLPEN_ERA</td>\n",
       "      <td>pitcher1_rgs</td>\n",
       "      <td>pitcher2_rgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_BULLPEN_WHIP</td>\n",
       "      <td>road_BULLPEN_WHIP</td>\n",
       "      <td>pitcher1_adj</td>\n",
       "      <td>pitcher2_adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home_BULLPEN_AVG_INNINGS</td>\n",
       "      <td>road_BULLPEN_AVG_INNINGS</td>\n",
       "      <td>rating_prob1</td>\n",
       "      <td>rating_prob2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_total_OBPS</td>\n",
       "      <td>road_total_OBPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_total_AVG_RUNS</td>\n",
       "      <td>road_total_AVG_RUNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_total_AVG_H</td>\n",
       "      <td>road_total_AVG_H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_total_BULLPEN_ERA</td>\n",
       "      <td>road_total_BULLPEN_ERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home_total_BULLPEN_WHIP</td>\n",
       "      <td>road_total_BULLPEN_WHIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_total_BULLPEN_AVG_INNINGS</td>\n",
       "      <td>road_total_BULLPEN_AVG_INNINGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_career_ERA</td>\n",
       "      <td>road_career_ERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_career_WHIP</td>\n",
       "      <td>road_career_WHIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_career_AVGIP</td>\n",
       "      <td>road_career_AVGIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_career_ERA_AH</td>\n",
       "      <td>road_career_ERA_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_career_WHIP_AH</td>\n",
       "      <td>road_career_WHIP_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home_career_AVGIP_AH</td>\n",
       "      <td>road_career_AVGIP_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home_season_ERA</td>\n",
       "      <td>road_season_ERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>home_season_WHIP</td>\n",
       "      <td>road_season_WHIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>home_season_AVGIP</td>\n",
       "      <td>road_season_AVGIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>home_season_ERA_AH</td>\n",
       "      <td>road_season_ERA_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home_season_WHIP_AH</td>\n",
       "      <td>road_season_WHIP_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>home_season_AVGIP_AH</td>\n",
       "      <td>road_season_AVGIP_OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0                               1  \\\n",
       "0                        home_OBPS                       road_OBPS   \n",
       "1                    home_AVG_RUNS                   road_AVG_RUNS   \n",
       "2                       home_AVG_H                      road_AVG_H   \n",
       "3                 home_BULLPEN_ERA                road_BULLPEN_ERA   \n",
       "4                home_BULLPEN_WHIP               road_BULLPEN_WHIP   \n",
       "5         home_BULLPEN_AVG_INNINGS        road_BULLPEN_AVG_INNINGS   \n",
       "6                  home_total_OBPS                 road_total_OBPS   \n",
       "7              home_total_AVG_RUNS             road_total_AVG_RUNS   \n",
       "8                 home_total_AVG_H                road_total_AVG_H   \n",
       "9           home_total_BULLPEN_ERA          road_total_BULLPEN_ERA   \n",
       "10         home_total_BULLPEN_WHIP         road_total_BULLPEN_WHIP   \n",
       "11  home_total_BULLPEN_AVG_INNINGS  road_total_BULLPEN_AVG_INNINGS   \n",
       "12                 home_career_ERA                 road_career_ERA   \n",
       "13                home_career_WHIP                road_career_WHIP   \n",
       "14               home_career_AVGIP               road_career_AVGIP   \n",
       "15              home_career_ERA_AH              road_career_ERA_OR   \n",
       "16             home_career_WHIP_AH             road_career_WHIP_OR   \n",
       "17            home_career_AVGIP_AH            road_career_AVGIP_OR   \n",
       "18                 home_season_ERA                 road_season_ERA   \n",
       "19                home_season_WHIP                road_season_WHIP   \n",
       "20               home_season_AVGIP               road_season_AVGIP   \n",
       "21              home_season_ERA_AH              road_season_ERA_OR   \n",
       "22             home_season_WHIP_AH             road_season_WHIP_OR   \n",
       "23            home_season_AVGIP_AH            road_season_AVGIP_OR   \n",
       "\n",
       "               2             3  \n",
       "0       elo1_pre      elo2_pre  \n",
       "1      elo_prob1     elo_prob2  \n",
       "2    rating1_pre   rating2_pre  \n",
       "3   pitcher1_rgs  pitcher2_rgs  \n",
       "4   pitcher1_adj  pitcher2_adj  \n",
       "5   rating_prob1  rating_prob2  \n",
       "6            NaN           NaN  \n",
       "7            NaN           NaN  \n",
       "8            NaN           NaN  \n",
       "9            NaN           NaN  \n",
       "10           NaN           NaN  \n",
       "11           NaN           NaN  \n",
       "12           NaN           NaN  \n",
       "13           NaN           NaN  \n",
       "14           NaN           NaN  \n",
       "15           NaN           NaN  \n",
       "16           NaN           NaN  \n",
       "17           NaN           NaN  \n",
       "18           NaN           NaN  \n",
       "19           NaN           NaN  \n",
       "20           NaN           NaN  \n",
       "21           NaN           NaN  \n",
       "22           NaN           NaN  \n",
       "23           NaN           NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset indices, combine like series into dataframe to look at feature names together\n",
    "home_team_retro = home_team_retro.reset_index(drop = True)\n",
    "road_team_retro = road_team_retro.reset_index(drop = True)\n",
    "home_team_elo = home_team_elo.reset_index(drop = True)\n",
    "road_team_elo = road_team_elo.reset_index(drop = True)\n",
    "\n",
    "#concat retro features together to examine side by side\n",
    "pd.concat([home_team_retro, road_team_retro, home_team_elo, road_team_elo], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_OBPS</th>\n",
       "      <th>_AVG_RUNS</th>\n",
       "      <th>_AVG_H</th>\n",
       "      <th>_BULLPEN_ERA</th>\n",
       "      <th>_BULLPEN_WHIP</th>\n",
       "      <th>_BULLPEN_AVG_INNINGS</th>\n",
       "      <th>_total_OBPS</th>\n",
       "      <th>_total_AVG_RUNS</th>\n",
       "      <th>_total_AVG_H</th>\n",
       "      <th>_total_BULLPEN_ERA</th>\n",
       "      <th>...</th>\n",
       "      <th>_season_AVGIP</th>\n",
       "      <th>_season_ERA_</th>\n",
       "      <th>_season_WHIP_</th>\n",
       "      <th>_season_AVGIP_</th>\n",
       "      <th>elo_pre</th>\n",
       "      <th>elo_prob</th>\n",
       "      <th>rating_pre</th>\n",
       "      <th>pitcher_rgs</th>\n",
       "      <th>pitcher_adj</th>\n",
       "      <th>rating_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.580</td>\n",
       "      <td>0.286959</td>\n",
       "      <td>82.454</td>\n",
       "      <td>16.116</td>\n",
       "      <td>-7.469379</td>\n",
       "      <td>0.282078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.333</td>\n",
       "      <td>0.118408</td>\n",
       "      <td>15.962</td>\n",
       "      <td>12.240</td>\n",
       "      <td>-7.498618</td>\n",
       "      <td>0.092876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.381792</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.381792</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.867</td>\n",
       "      <td>0.298241</td>\n",
       "      <td>85.646</td>\n",
       "      <td>11.399</td>\n",
       "      <td>-7.469379</td>\n",
       "      <td>0.285893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.365</td>\n",
       "      <td>0.124170</td>\n",
       "      <td>21.794</td>\n",
       "      <td>-2.222</td>\n",
       "      <td>-3.516115</td>\n",
       "      <td>0.132830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.376</td>\n",
       "      <td>0.325543</td>\n",
       "      <td>92.321</td>\n",
       "      <td>13.020</td>\n",
       "      <td>-17.146280</td>\n",
       "      <td>0.275615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _OBPS  _AVG_RUNS  _AVG_H  _BULLPEN_ERA  _BULLPEN_WHIP  \\\n",
       "0  0.000000        0.0     0.0           0.0            0.0   \n",
       "1  0.000000        0.0     0.0           0.0            0.0   \n",
       "2  0.381792        6.0     5.0           0.0           -1.5   \n",
       "3  0.000000        0.0     0.0           0.0            0.0   \n",
       "4  0.000000        0.0     0.0           0.0            0.0   \n",
       "\n",
       "   _BULLPEN_AVG_INNINGS  _total_OBPS  _total_AVG_RUNS  _total_AVG_H  \\\n",
       "0                   0.0     0.000000              0.0           0.0   \n",
       "1                   0.0     0.000000              0.0           0.0   \n",
       "2                  -2.0     0.381792              6.0           5.0   \n",
       "3                   0.0     0.000000              0.0           0.0   \n",
       "4                   0.0     0.000000              0.0           0.0   \n",
       "\n",
       "   _total_BULLPEN_ERA  ...  _season_AVGIP  _season_ERA_  _season_WHIP_  \\\n",
       "0                 0.0  ...            0.0           0.0            0.0   \n",
       "1                 0.0  ...            0.0           0.0            0.0   \n",
       "2                 0.0  ...            0.0           0.0            0.0   \n",
       "3                 0.0  ...            0.0           0.0            0.0   \n",
       "4                 0.0  ...            0.0           0.0            0.0   \n",
       "\n",
       "   _season_AVGIP_  elo_pre  elo_prob  rating_pre  pitcher_rgs  pitcher_adj  \\\n",
       "0             0.0   78.580  0.286959      82.454       16.116    -7.469379   \n",
       "1             0.0   17.333  0.118408      15.962       12.240    -7.498618   \n",
       "2             0.0   82.867  0.298241      85.646       11.399    -7.469379   \n",
       "3             0.0   19.365  0.124170      21.794       -2.222    -3.516115   \n",
       "4             0.0   93.376  0.325543      92.321       13.020   -17.146280   \n",
       "\n",
       "   rating_prob  \n",
       "0     0.282078  \n",
       "1     0.092876  \n",
       "2     0.285893  \n",
       "3     0.132830  \n",
       "4     0.275615  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create empty list to store series of stat differences (retrosheet)\n",
    "all_series = []\n",
    "#col names (retro)\n",
    "column_names = []\n",
    "\n",
    "#iterate through feature series, storing differential in all_series\n",
    "#to keep consistency with target variable, it will be (home value - road value), as target is (home_score - road_score)\n",
    "for j in range(len(home_team_retro)):\n",
    "    home_stat = home_team_retro.iloc[j]\n",
    "    #some stat names are formatted differently between home and road, account for those \n",
    "    if home_stat.split('_')[-1] != 'AH':\n",
    "        stat_category = home_stat.split('home')[1]\n",
    "        road_stat = '{}{}'.format('road', stat_category)\n",
    "        difference = X[home_stat] - X[road_stat]\n",
    "    else:\n",
    "        stat_category = home_stat.split('home')[1].split('AH')[0]\n",
    "        road_stat = '{}{}{}'.format('road', stat_category, 'OR')\n",
    "        difference = X[home_stat] - X[road_stat]\n",
    "    all_series.append(difference)\n",
    "    column_names.append(stat_category)\n",
    "#iterate through elo feature series\n",
    "for j in range(len(home_team_elo)):\n",
    "    home_stat = home_team_elo.iloc[j]\n",
    "    if home_stat.split('1')[1] != '':\n",
    "        stat_category = home_stat.split('1')[0] + '{}' + home_stat.split('1')[1]\n",
    "    else:\n",
    "        stat_category = home_stat.split('1')[0] + '{}'\n",
    "    road_stat = stat_category.format('2')\n",
    "    difference = X[home_stat] - X[road_stat]\n",
    "    stat_category = stat_category.replace('{}', '')\n",
    "    all_series.append(difference)\n",
    "    column_names.append(stat_category)\n",
    "\n",
    "#aggregate all series into dataframe     \n",
    "difference_frame = pd.concat(all_series, axis = 1)\n",
    "difference_frame.columns = column_names\n",
    "#view dataframe\n",
    "difference_frame.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT STEP: add back in non home/road features, run back through feature selector / check for baseline improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Modeling

## KPI / Evaluation Metrics

Looking from the outside in, it would seem that generating a gambling model based on team wins and team losses is a simple binary classification model. Binary classification has many different metrics to evaluate model performance: Accuracy, precision, F1-score, ROC Area Under the Curve, etc. However, none of these are sufficient in evaluating a gambling model. It is more than possible to achieve a high accuracy (relatively, accuracy in predicting baseball outcomes is never that high) and still produce a betting scheme that loses money. The FiveThirtyEight predictions demonstrate this point perfectly. FiveThirtyEight, as mentioned previously, maintains the MLB Elo model which is an extremely popular and successful baseball model and is considered somewhat of a gold standard in predictive power. For the 2019 baseball season, the FiveThirtyEight model accurately forecasts $59.82\%$ of baseball games. While building my own models that strictly predict game outcome, please see __SGDClassifiers.ipynb__, I was able to predict with very similar results, accurately forecasting $59.99\%$ of games. But look at the profit generated by the FiveThirtyEight scheme: 

![EloBase](neural_net/bankroll_images/elo_base.png)

Even though the games were predicted with almost $60\%$ accuracy, the betting scheme still loses money on the season. You'll also notice that the results are not a tremendous improvement upon just flipping a coin to decide each game.

![RandomChoice](neural_net/bankroll_images/random_base.png)

The reason being is the aforementioned VIG: Betting favorites, who win more frequently, yields lower payouts. The only metric that matters in evaluating betting schemes is bettor profit, and therefore this will be the only metric considered in evaluating models. 

## Methodology

There are many different ways to frame and approach this problem, and I have tried nearly all of them. The problem can be framed as a Regression problem, a Binary Classification problem, or a Multi-Class classification problem. While I would enjoy discussing all the different methods and their respective shortcomings and strengths, in the interest of time I will only discuss three methods that showed promising results. 

## Data
__NOTE: I am working on an entire feature / data exploration section where I outline what all the different features mean, this is not that__ The three models outlined below are all trained on different feature sets. I will include the features used in each model and the data preparation techniques within each model. However, the commonality of all models is that they were trained on data from past seasons and used to predict the 2019 season. The point is to use past seasons to build a model to predict the next season, so randomly splitting into training and validation sets did not make sense in this case. 

## Deep Learning - Binary Classification with Custom Loss Function

Standard loss functions used in Binary Classification, such as the Log-Loss function and Hinge loss, are not optimized for the task at hand. One way to work around this is to write a loss function that teaches a model how to identify good bets versus bad bets instead of wins versus losses. This loss function looks like this: 

$L\bigg(y, \hat{y}\bigg) = \displaystyle\sum_{i}^{n}\bigg(P_{1}^{(i)}*y-1\bigg)*ReLU\bigg(P_{1}^{(i)}*\hat{y} -1\bigg) + \bigg(P_{2}^{(i)}*(y-1)-1\bigg)*ReLU\bigg(P_{2}^{(i)}*(1 - \hat{y})-1\bigg)$

where 

* $P_{1}^{(i)}, P_{2}^{(i)}$ are the payouts of a correct bet placed on the home team and road team respectively. 
* $ReLU = \begin{cases} x & 0 \leq x \lt \infty \\ 0 &  x \lt 0 \end{cases}$

The $ReLU$ function (Rectified Linear Unit) simulates a betting strategy as it only "places" a bet when the value is greater than $0$ and whereas other loss functions punish inaccurate outcome prediction, this loss function punishes bets with no value. An example to illustrate this: Placing a 100 dollar bet on a $-340$ betting favorite has a potential payout of $29$ dollars if the betting favorite wins, while the potential is still $100$. There is limited value to winning such a bet with the same amount of risk as betting on a $+140$ underdog, which would payout $140$ dollars. Now, obviously, the $-340$ favorite will win more often than the $+140$ underdog, but this loss function searches for the bets with value.  

![NNOutline](neural_net/nn_5.svg)

The feature set used in this model was:
* Home Team and Road Team OPS (On-Base Percentage + Slugging Percentage)
* Home Team and Road Team Bullpen ERA (Earned Run Average of all relief pitchers)
* Home Starter and Road Starter career ERA (Earned Run Average of Starting Pitcher, career)
* Home and Road Starter season ERA (Earned Run Average of Starting Pitcher, season)
* Home record at home (Number of games above or below .500, 0-based)
* Average Margin of Victory or Loss for Home Team and Road Team
* Home opening moneyline (Betting moneyline for home team)
* Road team record on road (number of games above or below .500, 0-based)
* Current Streak for Home team and Road Team (Either record in last ten games, number of games above or below .500, or if they have won more than ten games in a row, number of consecutive wins) 

Features were selected recursively by training tree-based models (LightGBM, XGBoost, RandomForestClassifier) with 5-fold cross validation, removing the least important features, and re-training until performance stopped improving. Then I selected the features that were important to the all three algorithms. (__see FeatureSelector object in recursive_selection.py__) 

The model was trained using Keras, a high level Python API to train Neural Networks on top of the powerful Tensorflow library. Keras also has functionality to define and implement a custom loss function, which was critical to this particular model. The model is a Fully Connected Neural Network, and the architecture of the model as follows: __need to add math/more in-depth explanation here__

* Dense Input Layer - ReLU activations
* Batch Normalization Layer - Scale activations to Mean $0$ and Standard Deviation $1$.
* Dense Hidden Layer - ReLU activations
* Batch Normalization Layer
* Dense Hidden Layer- ReLu activations
* Batch Normalization Layer
* Dense Output Layer- Sigmoid activation

Each densely connected hidden layer contained 50 neurons. I experimented with many different configurations of model architecture and experimented with the use of Dropout layers to avoid overfitting, but this model produced the strongest results.

The model was compiled and trained with:
* Objective function: Custom (outlined above)
* Optimizer: Adam
* Learning rate: 0.001
* Batch size: 32
* Epochs: 100

The resulting scheme produced a vast improvement over the SGDClassifier and FiveThirtyEight predictions. 

![NNResults](neural_net/bankroll_images/deep_learning.png)

Taking this model further: 
The current model predicts every single game. A model that less plays with a higher winning rate would be ideal. For example, by only betting the underdogs, we can achieve half the profit with one sixth of the plays. 

![NNResults2](neural_net/bankroll_images/only_dogs.png)

This is not a perfect strategy: I'd like to avoid losing $2000$ dollars the first half of the season. But this is what I will continue to pursue - selecting which picks to use from the model.

## Regression - Line Prediction 

There are two ways to frame this as a regression problem. The first is to attempt to predict the final score of the game. This failed miserably: please see __01regression_attempt.ipynb__. However, there was a different way to frame the problem that proved more effective. Instead of predicting the outcome of the game, I built a model to predict the betting line and then generated a betting strategy using this model. 